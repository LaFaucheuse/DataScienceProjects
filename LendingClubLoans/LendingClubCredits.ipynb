{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LENDING CLUB CREDITS**\n",
    "\n",
    "In this project, we will study a financial issue : modeling a borrower's credit risk. For this, we use financial lending data from Lending Club, which is a marketplace for personal loans. It basically matches borrowers who are seeking a loan with investors looking to lend money and make a return.\n",
    "\n",
    "## **How Lending Club works**\n",
    "\n",
    "Each borrower must fill a comprehensive application containing various information, such as past financial history or the reason for the loan. Based on those data, the borrower is assigned a credit score and an interest rate according to Lending Club's own data science process. The interest rate corresponds to the percent in addition to the requested loan amount the borrower has to pay back. The higher the interest rate is, the riskier the borrower, who is unlekely to pay back the loan. A lower interest rate means higher chance that the borrower will pay the loan on time. The interest rates goes from 5.32% to 30.99% and each borrower is given a grade according to the assigned interest rate. The loan is listed on the Lending Club Marketplace once the borrower accepts the interest rate.\n",
    "\n",
    "Investors can browse information about borrowers like the credit score and decide who they want to loan their money. Once a loan has been accepted, the borrower makes monthly payments back to Lending Club either over 36 months or over 60 months. Lending Club then redistributes these payments to the investors that participated in a given loan, which means they don't have to wait until the amount is completely paid before getting a return in money.\n",
    "It is important for the investors to have the loan paid back on time, so that they can make a return which corresponds to the interest rate the borrower had to pay in addition to the requested amount. Unfortunately, it is frequent to see loans that are not completely paid on time.\n",
    "\n",
    "## **The data**\n",
    "\n",
    "Data for all of the approved and declined loan applications are realeased periodically on the Lending Club website. It is possible to download datasets for a given year range in CSV format. Datasets come with a data dictionary in XLS format, which contains information on the different column names. It is available here : https://docs.google.com/spreadsheets/d/191B2yJ4H1ZPXq0_ByhUgWMFZOYem5jFz0Y3by_7YBY4/edit\n",
    "\n",
    "\n",
    "The LoanStats sheet describes the approved loans datasets and the RejectStats describes the rejected loans datasets. We focus on data about approved loans only since rejected applications don't appear on the Lending Club marketplace and aren't available for investment. The approved loans datasets contain information on current loans, completed loans, and defaulted loans.\n",
    "\n",
    "## **Problematic**\n",
    "\n",
    "The aim of this project is to determine which loans are more likely to be paid off from the perspective of a conservative investor who only wants to invest in the loans that have a good chance of being paid off on time.\n",
    "\n",
    "How can we accurately predict if a borrower will pay off their loan on time ?\n",
    "\n",
    "We will use machine learning models to answer this question. We will use approved loans data from 2007 to 2011 for a better accuracy, since most of the loans have already finished.\n",
    "\n",
    "## **Data preparation**\n",
    "\n",
    "We need to define a target column to make our predicitons on, and figure out which features we are going to use in our model. Let's have a look at the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galak\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                1077501\n",
      "member_id                      1.2966e+06\n",
      "loan_amnt                            5000\n",
      "funded_amnt                          5000\n",
      "funded_amnt_inv                      4975\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "grade                                   B\n",
      "sub_grade                              B2\n",
      "emp_title                             NaN\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "issue_d                          Dec-2011\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "zip_code                            860xx\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                 Jan-1985\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                          83.7%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "out_prncp                               0\n",
      "out_prncp_inv                           0\n",
      "total_pymnt                       5863.16\n",
      "total_pymnt_inv                   5833.84\n",
      "total_rec_prncp                      5000\n",
      "total_rec_int                      863.16\n",
      "total_rec_late_fee                      0\n",
      "recoveries                              0\n",
      "collection_recovery_fee                 0\n",
      "last_pymnt_d                     Jan-2015\n",
      "last_pymnt_amnt                    171.62\n",
      "last_credit_pull_d               Jun-2016\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               INDIVIDUAL\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loans_2007 = pd.read_csv(\"loans_2007.csv\")\n",
    "loans_2007.drop_duplicates()\n",
    "print(loans_2007.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Target column definition**\n",
    "\n",
    "The loan_status column is the only column that directly provides information on the payment of a loan. It tells if the loan was paid off on time, had delayed payments, or was defaulted on the borrower. To be able to use this column for the training model, the text needs to be converted into a numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid                                             33136\n",
      "Charged Off                                             5634\n",
      "Does not meet the credit policy. Status:Fully Paid      1988\n",
      "Current                                                  961\n",
      "Does not meet the credit policy. Status:Charged Off      761\n",
      "Late (31-120 days)                                        24\n",
      "In Grace Period                                           20\n",
      "Late (16-30 days)                                          8\n",
      "Default                                                    3\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans_2007['loan_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict if a loan will get paid on time or not, we are interested if the loan has been paid or charged off. The other categories are not relevant to make the predictions because they relate to ongoing loans and can be removed.\n",
    "\n",
    "We can use a binary classification for our variable, 1 for fully paid loans, 0 for charged off loans. However, there is a class imbalance between the positive and negative classes and this must be considered when buidling the model, as it could lead to a strong bias towards positive outcomes.\n",
    "\n",
    "Let's remove all the values that do not matter and assign 1 and 0 to respectively paid and charged off loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007[(loans_2007['loan_status'] == \"Fully Paid\") | (loans_2007['loan_status'] == \"Charged Off\")]\n",
    "\n",
    "status_replace = {\n",
    "    \"loan_status\" : {\n",
    "        \"Fully Paid\": 1,\n",
    "        \"Charged Off\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "loans_2007 = loans_2007.replace(status_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Features selection**\n",
    "\n",
    "Features must follow some guidelines :\n",
    "\n",
    "  -they must not leak information from the future (after the loan has already been funded). This could cause overfitting.\n",
    "  -they don't affect a borrower's ability to pay back a loan (e.g. a randomly generated ID value by Lending Club)\n",
    "\n",
    "We should avoid features whose data are formatted poorly and need to be cleaned up, require more data or a lot of processing to turn into a useful feature, or contain redundant information.\n",
    "\n",
    "Let's first remove the columns we don't need at first sight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                            5000\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "loan_status                             1\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                 Jan-1985\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                          83.7%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "last_credit_pull_d               Jun-2016\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               INDIVIDUAL\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "loans_2007 = loans_2007.drop([\"id\", \"member_id\", \"funded_amnt\", \"funded_amnt_inv\", \"grade\", \"sub_grade\", \"emp_title\", \"issue_d\", \"zip_code\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\"], axis=1)\n",
    "print(loans_2007.iloc[0])\n",
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the retained features and check if they bring or not useful input for the model. Some features have in fact only one value and must be droped. For each column, we first eliminate NA values and then eliminate the columns containing only one value and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "orig_columns = loans_2007.columns\n",
    "drop_columns = []\n",
    "for col in orig_columns:\n",
    "    col_series = loans_2007[col].dropna().unique()\n",
    "    if len(col_series) == 1:\n",
    "        drop_columns.append(col)\n",
    "loans_2007 = loans_2007.drop(drop_columns, axis=1)\n",
    "print(drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_length              1036\n",
      "title                     11\n",
      "revol_util                50\n",
      "last_credit_pull_d         2\n",
      "pub_rec_bankruptcies     697\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = loans_2007.isnull().sum()\n",
    "print(null_counts[null_counts>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables emp_length and pub_rec_bankruptices contain many missing values. Employment length is frequently used as an indicator to assess how risky a potential borrower is, and it should not be wise to eliminate this column. Let's check the pub_rec_bankruptcies variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.939438\n",
      "1.0    0.042456\n",
      "NaN    0.017978\n",
      "2.0    0.000129\n",
      "Name: pub_rec_bankruptcies, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(loans_2007.pub_rec_bankruptcies.value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that nearly 94% of this column have the same value, which indicates a low variability, we can eliminate this column of the features set. The missing values of the other columns are scarce and we can safely remove the rows containing them only once the pub_rec_bankruptcies variable has been removed (to avoid eliminating the rows with missing values in this column). Let's also analyse the types of the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     11\n",
      "float64    10\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "loans_2007 = loans_2007.drop(\"pub_rec_bankruptcies\", axis=1)\n",
    "loans_2007 = loans_2007.dropna(axis=0)\n",
    "print(loans_2007.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features of the \"object\" type must be converted to numerical data types in order to be used with the scikit-learn library. Let's create a dataframe containing only those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                     36 months\n",
      "int_rate                    10.65%\n",
      "emp_length               10+ years\n",
      "home_ownership                RENT\n",
      "verification_status       Verified\n",
      "purpose                credit_card\n",
      "title                     Computer\n",
      "addr_state                      AZ\n",
      "earliest_cr_line          Jan-1985\n",
      "revol_util                   83.7%\n",
      "last_credit_pull_d        Jun-2016\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "object_columns_df = loans_2007.select_dtypes(include=[\"object\"])\n",
    "print(object_columns_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns represent numeric values and to be converted:\n",
    "\n",
    "int_rate: interest rate of the loan in %\n",
    "revol_util: revolving line utilization rate or the amount of credit the borrower is using relative to all available credit\n",
    "\n",
    "Some features seem to be categorical variables, we use the dictionnary to confirm and check how many categories they have :\n",
    "\n",
    "home_ownership: home ownership status, can only be 1 of 4 categorical variables\n",
    "verification_status: indicates if income was verified by Lending Club\n",
    "emp_length: number of years the borrower was employed upon time of application\n",
    "term: number of payments on the loan, either 36 or 60\n",
    "addr_state: borrower's state of residence\n",
    "purpose: a category provided by the borrower for the loan request\n",
    "title: loan title provided by the borrower\n",
    "\n",
    "The columns purpose and title seem to reflect the same information. Let's explore the unique value counts separately to confirm if this is true, and drop one of those columns accordingly.\n",
    "\n",
    "Lastly, some of the columns contain date values that require considerable engineering before being potentially useful:\n",
    "\n",
    "earliest_cr_line: The month the borrower's earliest reported credit line was opened\n",
    "last_credit_pull_d: The most recent month Lending Club pulled credit for this loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT        18112\n",
      "MORTGAGE    16686\n",
      "OWN          2778\n",
      "OTHER          96\n",
      "NONE            3\n",
      "Name: home_ownership, dtype: int64\n",
      "Not Verified       16281\n",
      "Verified           11856\n",
      "Source Verified     9538\n",
      "Name: verification_status, dtype: int64\n",
      "10+ years    8545\n",
      "< 1 year     4513\n",
      "2 years      4303\n",
      "3 years      4022\n",
      "4 years      3353\n",
      "5 years      3202\n",
      "1 year       3176\n",
      "6 years      2177\n",
      "7 years      1714\n",
      "8 years      1442\n",
      "9 years      1228\n",
      "Name: emp_length, dtype: int64\n",
      " 36 months    28234\n",
      " 60 months     9441\n",
      "Name: term, dtype: int64\n",
      "CA    6776\n",
      "NY    3614\n",
      "FL    2704\n",
      "TX    2613\n",
      "NJ    1776\n",
      "IL    1447\n",
      "PA    1442\n",
      "VA    1347\n",
      "GA    1323\n",
      "MA    1272\n",
      "OH    1149\n",
      "MD    1008\n",
      "AZ     807\n",
      "WA     788\n",
      "CO     748\n",
      "NC     729\n",
      "CT     711\n",
      "MI     678\n",
      "MO     648\n",
      "MN     581\n",
      "NV     466\n",
      "SC     454\n",
      "WI     427\n",
      "OR     422\n",
      "LA     420\n",
      "AL     420\n",
      "KY     311\n",
      "OK     285\n",
      "UT     249\n",
      "KS     249\n",
      "AR     229\n",
      "DC     209\n",
      "RI     194\n",
      "NM     180\n",
      "WV     164\n",
      "HI     162\n",
      "NH     157\n",
      "DE     110\n",
      "MT      77\n",
      "AK      76\n",
      "WY      76\n",
      "SD      60\n",
      "VT      53\n",
      "MS      19\n",
      "TN      17\n",
      "IN       9\n",
      "ID       6\n",
      "NE       5\n",
      "IA       5\n",
      "ME       3\n",
      "Name: addr_state, dtype: int64\n",
      "\n",
      "\n",
      "Debt Consolidation                          2068\n",
      "Debt Consolidation Loan                     1599\n",
      "Personal Loan                                624\n",
      "Consolidation                                488\n",
      "debt consolidation                           466\n",
      "                                            ... \n",
      "Credit Consolidator                            1\n",
      "Argon 18                                       1\n",
      "Just need some help to become debt free!       1\n",
      "Dentaldebt                                     1\n",
      "Visa payoff                                    1\n",
      "Name: title, Length: 18881, dtype: int64\n",
      "\n",
      "\n",
      "debt_consolidation    17751\n",
      "credit_card            4911\n",
      "other                  3711\n",
      "home_improvement       2808\n",
      "major_purchase         2083\n",
      "small_business         1719\n",
      "car                    1459\n",
      "wedding                 916\n",
      "medical                 655\n",
      "moving                  552\n",
      "house                   356\n",
      "vacation                348\n",
      "educational             312\n",
      "renewable_energy         94\n",
      "Name: purpose, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "for c in cols:\n",
    "    print(loans_2007[c].value_counts())\n",
    "print(\"\\n\")\n",
    "print(loans_2007[\"title\"].value_counts())\n",
    "print(\"\\n\")\n",
    "print(loans_2007[\"purpose\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emp_length column should be cleaned and treated as a numerical feature since the values have ordering. THis implies making some assumptions : people having worked less than one year are considered as not having worked, and people having worked more than 10 years are considered to have only really worked 10 years. It is fine to make those assumptions in our case, since we consider the perspective of conservative investors that prefers missing out opportunities than risking unpaid loans. We use a dictionary in order to use the replace function to create the new numerical categories.\n",
    "\n",
    "The home_ownership, verification_status, and term columns each contain a few discrete categorical values and should converted to dummy variables.\n",
    "\n",
    "It seems like the purpose and title columns do contain overlapping information. We keep the purpose column as it contains less discrete values than the title column, which additionally shows some data quality issues (many of the values are repeated with slight modifications (e.g. Debt Consolidation and Debt Consolidation Loan and debt consolidation).\n",
    "\n",
    "We also remove the addr_state column as it contains multiple values that would make it too heavy for dummy conversion within the dataframe.\n",
    "\n",
    "Let's directly drop the earliest_cr_line and last_credit_pull_d columns since the amount of information they bring might not be as useful in comparison to the time spent on engineering them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "loans_2007 = loans_2007.drop([\"last_credit_pull_d\", \"earliest_cr_line\", \"addr_state\", \"title\"], axis=1)\n",
    "loans_2007[\"int_rate\"] = loans_2007[\"int_rate\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans_2007[\"revol_util\"] = loans_2007[\"revol_util\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans_2007 = loans_2007.replace(mapping_dict)\n",
    "\n",
    "\n",
    "cat_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "dummy_df = pd.get_dummies(loans_2007[cat_columns])\n",
    "loans_2007 = pd.concat([loans_2007, dummy_df], axis=1)\n",
    "loans_2007 = loans_2007.drop(cat_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL**\n",
    "\n",
    "### **Error metric**\n",
    "\n",
    "The data are now prepared to feed the model. Before choosing the adequate model, we must select an error metric to evaluate how the model performs. Let's have a quick recap on our problematic : we want to enable enough loans that will be paid off on time to be able to gain the interests and have a positive balance over money loss due to unpaid loans. The error metric should help us determine if our algorithm will make the investors win or lose money. \n",
    "\n",
    "We are trying to predict the binary loan_status variable, which enables missclassifications issues : false positive and false negative. Since we took the perspective of conservative investors, who prefer missing out on opportunities (false negatives) than funding a risky loan (false positives), we should carefully consider the latter. Let's also remember that we are dealing with imbalance data that would tend to favor false positives.\n",
    "\n",
    "Therefore, accuracy might not be the best metric to measure our model's performance, but rather the false and true positives rates (fpr and tpr respectively), defined as follow :\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "with: \n",
    "tp = true positives\n",
    "tn = true negatives\n",
    "fp = false positive\n",
    "fn = false negative\n",
    "\n",
    "Logistic regression is a good model to start when dealing with binary classification problems. To adress the imbalance between positive and negative outcomes, we set class_weight to \"balanced\" when creating the LogisticRegression instance in order to penalize the misclassification of the minority class during the training process.\n",
    "\n",
    "\n",
    "Let's now start our prediction attempt with a logistic regression model, adapted for binary classification problems. We create a dataframe containing all the previously selected features, and a serie containing the target variable \"loan_status\". To avoid overfitting, we use a k-fold cross validation on the logistic regression model. We then calculate the fpr and tpr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Galak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5465718405873099\n",
      "0.5237907206317868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "# Creation of features dataframe and target serie\n",
    "cols = loans_2007.columns\n",
    "train_cols = cols.drop(\"loan_status\")\n",
    "features = loans_2007[train_cols]\n",
    "target = loans_2007[\"loan_status\"]\n",
    "\n",
    "# Performing k-fold cross validation on the logistic regression model with balanced class_weight\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans_2007[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans_2007[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans_2007[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans_2007[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "# Rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get more than 50% for true and false positives rates. While it's good for true positive, it is still quite high for false positive. Let's try to decrease the false positive rate by manually tweaking the class_weight penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1704902988987939\n",
      "0.16722606120434352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Setting penalty values for the class-weight argument\n",
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "#Performing k-fold cross validation on the logistic regression model with manual values for the class_weight argument\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans_2007[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans_2007[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans_2007[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans_2007[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually changing the penalty values considerably reduced the false positive rate, but also came with the cost of reducing the true positives rate. We could keep experimenting those penalty values to reach a better compromise, but it might be useful to test another model to make our predictions.\n",
    "\n",
    "Let's test the randomforestclassifier model on our data. We set random_state to 1 to avoid variation of the predictions due to random chance, and set the class_weight with the previously used penalty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9964931830099633\n",
      "0.9970384995064165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Setting penalty values for the class-weight argument\n",
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "# Performing k-fold cross validation on the random forest model with manual penalty values class_weight\n",
    "rf = RandomForestClassifier(class_weight=penalty, random_state=1)\n",
    "predictions = cross_val_predict(rf, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans_2007[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans_2007[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans_2007[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans_2007[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the random forest model did not bring any improvment over the logistic regression model. It could be fixed by applying a harsher penalty for misclassifications of 0s.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Ultimately, our best model had a false positive rate of nearly 16%, and a true positive rate of nearly 17%. For a conservative investor, this means that they make money as long as the interest rate is high enough to offset the losses from 16% of borrowers defaulting, and that the pool of 17% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "This is not optimum, and there's still room to improve. Some next steps could be :\n",
    "\n",
    "Tweak the penalties further.\n",
    "Try models other than a random forest and logistic regression.\n",
    "Ensemble multiple models to get more accurate predictions.\n",
    "Tune the parameters of the algorithm to achieve higher performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
